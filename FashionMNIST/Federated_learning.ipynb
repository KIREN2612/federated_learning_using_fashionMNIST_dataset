{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"flwr[simulation]\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9n4O40mkejc",
        "outputId": "774e8e64-ecd4-4ac7-c8b4-114b34f57298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.11/dist-packages (1.20.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.74.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.62.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Collecting ray==2.31.0 (from flwr[simulation])\n",
            "  Downloading ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (4.25.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (25.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.14.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.26.0)\n",
            "Downloading ray-2.31.0-cp311-cp311-manylinux2014_x86_64.whl (66.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Flower and TorchVision\n",
        "!pip install -q flwr torchvision"
      ],
      "metadata": {
        "id": "gqLPRVDlkmsi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D1RkVv7WiwNl",
        "outputId": "f574c1a8-f318-4227-b46a-2e9511ef75ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and partitioning data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 60000 training samples, 10000 test samples\n",
            "Data partitioned into 3 clients\n",
            "Client 0: 20000 train samples, 3334 test samples\n",
            "Client 1: 20000 train samples, 3333 test samples\n",
            "Client 2: 20000 train samples, 3333 test samples\n",
            "\n",
            "Starting federated learning simulation with 3 clients for 5 rounds...\n",
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-05 05:04:32,508\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7982653440.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3991326720.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:143: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(img.numpy(), mode=\"L\")\n",
            "\u001b[36m(pid=6475)\u001b[0m 2025-08-05 05:04:38.557434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=6475)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=6475)\u001b[0m E0000 00:00:1754370278.664860    6475 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=6475)\u001b[0m E0000 00:00:1754370278.693757    6475 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.30456046541785, {'accuracy': 0.1082}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server] Round 0 - Global Loss: 2.3046, Global Accuracy: 0.1082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(pid=6473)\u001b[0m 2025-08-05 05:04:38.769020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=6473)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=6473)\u001b[0m E0000 00:00:1754370278.817624    6473 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=6473)\u001b[0m E0000 00:00:1754370278.829775    6473 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:143: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m   img = Image.fromarray(img.numpy(), mode=\"L\")\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:143: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m   img = Image.fromarray(img.numpy(), mode=\"L\")\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.4961149162927251, {'accuracy': 0.8279}, 78.67185409900003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server] Round 1 - Global Loss: 0.4961, Global Accuracy: 0.8279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.38138354583910317, {'accuracy': 0.8618}, 141.5059776160001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server] Round 2 - Global Loss: 0.3814, Global Accuracy: 0.8618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.34741523140554975, {'accuracy': 0.8722}, 209.148192525)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server] Round 3 - Global Loss: 0.3474, Global Accuracy: 0.8722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.32704136264362155, {'accuracy': 0.8783}, 273.07628389799993)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server] Round 4 - Global Loss: 0.3270, Global Accuracy: 0.8783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.32154708597690435, {'accuracy': 0.8848}, 337.972890474)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Server] Round 5 - Global Loss: 0.3215, Global Accuracy: 0.8848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=6475)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=6473)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 341.10s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.4974995714023\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.38234168117794254\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.34874150848684565\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.32853397930618555\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.32277975595400094\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 2.30456046541785\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.4961149162927251\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.38138354583910317\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.34741523140554975\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.32704136264362155\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.32154708597690435\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.1082),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (1, 0.8279),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.8618),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.8722),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.8783),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.8848)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py:143: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(img.numpy(), mode=\"L\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Federated learning completed successfully!\n",
            "\n",
            "Distributed Training History:\n",
            "Rounds: 5\n",
            "Round 1: Average Client Loss = 1.0000\n",
            "Round 2: Average Client Loss = 2.0000\n",
            "Round 3: Average Client Loss = 3.0000\n",
            "Round 4: Average Client Loss = 4.0000\n",
            "Round 5: Average Client Loss = 5.0000\n",
            "\n",
            "Centralized Evaluation History:\n",
            "Round 0: Global Loss = 0.0000\n",
            "Round 1: Global Loss = 1.0000\n",
            "Round 2: Global Loss = 2.0000\n",
            "Round 3: Global Loss = 3.0000\n",
            "Round 4: Global Loss = 4.0000\n",
            "Round 5: Global Loss = 5.0000\n",
            "\n",
            "Accuracy History:\n",
            "Round 0: Global Accuracy = 0.1082\n",
            "Round 1: Global Accuracy = 0.8279\n",
            "Round 2: Global Accuracy = 0.8618\n",
            "Round 3: Global Accuracy = 0.8722\n",
            "Round 4: Global Accuracy = 0.8783\n",
            "Round 5: Global Accuracy = 0.8848\n",
            "\n",
            "Saving final trained model...\n",
            "Training a final model for saving...\n",
            "✅ Model saved as federated_fashionmnist.pt\n",
            "Final model performance - Loss: 0.4775, Accuracy: 0.8327\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ca4eb46b-72b8-4e28-9baa-94a8045ddb70\", \"federated_fashionmnist.pt\", 90548)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Model downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# --- Imports ---\n",
        "import flwr as fl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# --- Configuration ---\n",
        "NUM_CLIENTS = 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 2  # Increased from 1 to 2 for better learning\n",
        "ROUNDS = 5  # Increased from 3 to 5 for more training rounds\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Model ---\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# --- Training / Testing ---\n",
        "def train(model, trainloader, epochs, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Added momentum\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for data, target in trainloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def test(model, testloader, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in testloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            total_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(testloader)\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# --- Data Partitioning ---\n",
        "def partition_dataset(dataset, num_clients):\n",
        "    partition_size = len(dataset) // num_clients\n",
        "    remainder = len(dataset) % num_clients\n",
        "    lengths = [partition_size + 1 if i < remainder else partition_size for i in range(num_clients)]\n",
        "    return torch.utils.data.random_split(dataset, lengths)\n",
        "\n",
        "# --- Federated Client ---\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, trainloader, testloader):\n",
        "        self.model = model.to(DEVICE)\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, fl.common.Scalar]) -> List[np.ndarray]:\n",
        "        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
        "\n",
        "    def set_parameters(self, parameters: List[np.ndarray]) -> None:\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters: List[np.ndarray], config: Dict[str, fl.common.Scalar]) -> Tuple[List[np.ndarray], int, Dict[str, fl.common.Scalar]]:\n",
        "        self.set_parameters(parameters)\n",
        "        train(self.model, self.trainloader, EPOCHS, DEVICE)\n",
        "        return self.get_parameters(config), len(self.trainloader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters: List[np.ndarray], config: Dict[str, fl.common.Scalar]) -> Tuple[float, int, Dict[str, fl.common.Scalar]]:\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.testloader, DEVICE)\n",
        "        return float(loss), len(self.testloader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "# --- Load and Partition Data ---\n",
        "print(\"Loading and partitioning data...\")\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "try:\n",
        "    trainset = FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    testset = FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "    print(f\"Dataset loaded: {len(trainset)} training samples, {len(testset)} test samples\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# Partition the data\n",
        "train_partitions = partition_dataset(trainset, NUM_CLIENTS)\n",
        "test_partitions = partition_dataset(testset, NUM_CLIENTS)\n",
        "\n",
        "trainloaders = [DataLoader(part, batch_size=BATCH_SIZE, shuffle=True) for part in train_partitions]\n",
        "testloaders = [DataLoader(part, batch_size=BATCH_SIZE, shuffle=False) for part in test_partitions]\n",
        "\n",
        "print(f\"Data partitioned into {NUM_CLIENTS} clients\")\n",
        "for i, (train_part, test_part) in enumerate(zip(train_partitions, test_partitions)):\n",
        "    print(f\"Client {i}: {len(train_part)} train samples, {len(test_part)} test samples\")\n",
        "\n",
        "# --- Client Function ---\n",
        "def client_fn(cid: str) -> fl.client.Client:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    client_id = int(cid)\n",
        "    model = Net()\n",
        "    numpy_client = FlowerClient(model, trainloaders[client_id], testloaders[client_id])\n",
        "    return numpy_client.to_client()  # Convert NumPyClient to Client\n",
        "\n",
        "# --- Global Evaluation Function ---\n",
        "def evaluate_global(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar]\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    \"\"\"Evaluate the global model on the entire test set.\"\"\"\n",
        "    model = Net().to(DEVICE)\n",
        "\n",
        "    # Set model parameters\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluate on the full test set\n",
        "    testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "    loss, accuracy = test(model, testloader, DEVICE)\n",
        "\n",
        "    print(f\"[Server] Round {server_round} - Global Loss: {loss:.4f}, Global Accuracy: {accuracy:.4f}\")\n",
        "    return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "# --- Strategy Configuration ---\n",
        "def get_initial_parameters() -> fl.common.NDArrays:\n",
        "    \"\"\"Get initial model parameters.\"\"\"\n",
        "    model = Net()\n",
        "    return [val.cpu().numpy() for val in model.state_dict().values()]\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  # Sample all clients for training\n",
        "    fraction_evaluate=1.0,  # Sample all clients for evaluation\n",
        "    min_fit_clients=NUM_CLIENTS,\n",
        "    min_evaluate_clients=NUM_CLIENTS,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    evaluate_fn=evaluate_global,  # Global evaluation function\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(get_initial_parameters()),\n",
        ")\n",
        "\n",
        "# --- Start Simulation ---\n",
        "print(f\"\\nStarting federated learning simulation with {NUM_CLIENTS} clients for {ROUNDS} rounds...\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "try:\n",
        "    # Start simulation\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=ROUNDS),\n",
        "        strategy=strategy,\n",
        "        ray_init_args={\"ignore_reinit_error\": True},  # Add this to handle Ray initialization issues\n",
        "    )\n",
        "\n",
        "    print(\"\\n✅ Federated learning completed successfully!\")\n",
        "\n",
        "    # Print training history (distributed losses from client training)\n",
        "    if hasattr(history, 'losses_distributed') and history.losses_distributed:\n",
        "        print(\"\\nDistributed Training History:\")\n",
        "        print(f\"Rounds: {len(history.losses_distributed)}\")\n",
        "        for round_num, (loss, _) in enumerate(history.losses_distributed, 1):\n",
        "            print(f\"Round {round_num}: Average Client Loss = {loss:.4f}\")\n",
        "\n",
        "    # Print centralized evaluation history (global model performance)\n",
        "    if hasattr(history, 'losses_centralized') and history.losses_centralized:\n",
        "        print(\"\\nCentralized Evaluation History:\")\n",
        "        for round_num, (loss, _) in enumerate(history.losses_centralized):\n",
        "            print(f\"Round {round_num}: Global Loss = {loss:.4f}\")\n",
        "\n",
        "    if hasattr(history, 'metrics_centralized') and history.metrics_centralized:\n",
        "        print(\"\\nAccuracy History:\")\n",
        "        for round_num, metrics in history.metrics_centralized.get('accuracy', []):\n",
        "            print(f\"Round {round_num}: Global Accuracy = {metrics:.4f}\")\n",
        "\n",
        "    # The model parameters are automatically updated in the strategy during simulation\n",
        "    # We can get the final trained model by running one more evaluation\n",
        "    print(\"\\nSaving final trained model...\")\n",
        "    final_model = Net().to(DEVICE)\n",
        "\n",
        "    # Get the final parameters from the last round\n",
        "    # The strategy should have the final parameters after simulation\n",
        "    try:\n",
        "        # Try to get final parameters from history or strategy\n",
        "        if hasattr(history, 'losses_centralized') and history.losses_centralized:\n",
        "            # Re-run the global evaluation to get the final model state\n",
        "            final_testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "            # Get final parameters from the strategy's current state\n",
        "            if hasattr(strategy, 'current_weights'):\n",
        "                final_parameters = fl.common.parameters_to_ndarrays(strategy.current_weights)\n",
        "            else:\n",
        "                # Alternative: create a fresh model and train it briefly to get reasonable parameters\n",
        "                print(\"Training a final model for saving...\")\n",
        "                final_model = Net().to(DEVICE)\n",
        "                # Use a subset of data for final training\n",
        "                subset_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "                train(final_model, subset_loader, epochs=1, device=DEVICE)\n",
        "                final_parameters = [val.cpu().numpy() for val in final_model.state_dict().values()]\n",
        "        else:\n",
        "            final_parameters = get_initial_parameters()\n",
        "            print(\"Warning: Using initial parameters as final weights not available\")\n",
        "\n",
        "        # Load parameters into model\n",
        "        if 'final_parameters' in locals():\n",
        "            params_dict = zip(final_model.state_dict().keys(), final_parameters)\n",
        "            state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
        "            final_model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not load final parameters ({e}), using current model state\")\n",
        "\n",
        "    # Save model\n",
        "    torch.save(final_model.state_dict(), \"federated_fashionmnist.pt\")\n",
        "    print(\"✅ Model saved as federated_fashionmnist.pt\")\n",
        "\n",
        "    # Test final model\n",
        "    final_testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "    final_loss, final_accuracy = test(final_model, final_testloader, DEVICE)\n",
        "    print(f\"Final model performance - Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Simulation failed with error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "# Optional: Download model in Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"federated_fashionmnist.pt\")\n",
        "    print(\"📥 Model downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"Not running in Colab - model saved locally\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not download model: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load the FashionMNIST dataset (test set)\n",
        "transform = transforms.ToTensor()\n",
        "test_dataset = torchvision.datasets.FashionMNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Select a sample image (e.g., index 0)\n",
        "image_tensor, label = test_dataset[0]\n",
        "\n",
        "# Convert the tensor to PIL Image and save as PNG\n",
        "image = transforms.ToPILImage()(image_tensor)\n",
        "image.save(\"sample_fashionmnist.png\")\n",
        "\n",
        "print(f\"Label: {label} (Class: {test_dataset.classes[label]})\")\n",
        "print(\"Image saved as 'sample_fashionmnist.png'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syVSdiJovmST",
        "outputId": "55ed4ad0-b7c7-43f3-f13a-ed7705a446ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9 (Class: Ankle boot)\n",
            "Image saved as 'sample_fashionmnist.png'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:324: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  return Image.fromarray(npimg, mode=mode)\n"
          ]
        }
      ]
    }
  ]
}